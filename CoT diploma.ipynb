{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: datasets in ./lib/python3.13/site-packages (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./lib/python3.13/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in ./lib/python3.13/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./lib/python3.13/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./lib/python3.13/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./lib/python3.13/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in ./lib/python3.13/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in ./lib/python3.13/site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./lib/python3.13/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in ./lib/python3.13/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./lib/python3.13/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./lib/python3.13/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./lib/python3.13/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./lib/python3.13/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./lib/python3.13/site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./lib/python3.13/site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./lib/python3.13/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./lib/python3.13/site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: six>=1.5 in ./lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Пример GPT-промпта ===\n",
      "User previously watched and rated the following movies:\n",
      "Moana (2016) | Genres: Adventure|Animation|Children|Comedy|Fantasy | Rating: 4.5\n",
      "Now, please provide your ratings (from 1 to 5) for the following movies:\n",
      "Hotel Transylvania 2 (2015) | Genres: Animation|Comedy\n",
      "--- Истинные оценки для валидации ---\n",
      "[{'title': 'Hotel Transylvania 2 (2015)', 'genres': 'Animation|Comedy', 'true_rating': 3.5}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "# Загружаем датасет MovieLens (train split)\n",
    "dataset = load_dataset(\"ashraq/movielens_ratings\", split=\"train\")\n",
    "\n",
    "# Уменьшаем размер выборки для примера\n",
    "n = 2000\n",
    "small_dataset = dataset.select(range(n))\n",
    "df = pd.DataFrame(small_dataset)\n",
    "\n",
    "# Сортируем оценки по user_id и по времени просмотра\n",
    "df = df.sort_values(['user_id'])\n",
    "\n",
    "# Делим на train/val индексы для \"истории\" и \"фильмов для оценки\"\n",
    "val_share = 0.2\n",
    "user2indices = defaultdict(list)\n",
    "for idx, user_id in enumerate(df['user_id']):\n",
    "    user2indices[user_id].append(idx)\n",
    "\n",
    "user_prompts = []\n",
    "\n",
    "for user_id, indices in user2indices.items():\n",
    "    n_hist = max(1, int(len(indices) * (1 - val_share)))\n",
    "    history_idxs = indices[:n_hist]\n",
    "    val_idxs = indices[n_hist:]\n",
    "    if not val_idxs:\n",
    "        continue  # Пропускаем юзеров только с историей\n",
    "    \n",
    "    # Формируем часть с историей\n",
    "    history_movies = df.iloc[history_idxs]\n",
    "    history_prompt = \"User previously watched and rated the following movies:\\n\"\n",
    "    for i, row in history_movies.iterrows():\n",
    "        history_prompt += (\n",
    "            f\"{row['title']} | Genres: {row['genres']} | Rating: {row['rating']}\\n\"\n",
    "        )\n",
    "    history_prompt = history_prompt.strip()\n",
    "    \n",
    "    # Формируем часть с новыми фильмами для оценки (ground truth rating при необходимости можно добавить для сравнения)\n",
    "    validation_movies = df.iloc[val_idxs]\n",
    "    movies_to_rate_prompt = \"\\nNow, please provide your ratings (from 1 to 5) for the following movies:\\n\"\n",
    "    for i, row in validation_movies.iterrows():\n",
    "        movies_to_rate_prompt += (\n",
    "            f\"{row['title']} | Genres: {row['genres']}\\n\"\n",
    "        )\n",
    "    movies_to_rate_prompt = movies_to_rate_prompt.strip()\n",
    "\n",
    "    prompt = history_prompt + \"\\n\" + movies_to_rate_prompt\n",
    "\n",
    "    # Можно добавить ground truth для валидации\n",
    "    ground_truth = [\n",
    "        {\n",
    "            \"title\": row[\"title\"],\n",
    "            \"genres\": row[\"genres\"],\n",
    "            \"true_rating\": row[\"rating\"],\n",
    "        }\n",
    "        for _, row in validation_movies.iterrows()\n",
    "    ]\n",
    "    \n",
    "    user_prompts.append({\n",
    "        \"user_id\": user_id,\n",
    "        \"prompt\": prompt,\n",
    "        \"ground_truth\": ground_truth\n",
    "    })\n",
    "\n",
    "# Пример одного промпта:\n",
    "print(\"=== Пример GPT-промпта ===\")\n",
    "print(user_prompts[0][\"prompt\"])\n",
    "print(\"--- Истинные оценки для валидации ---\")\n",
    "print(user_prompts[0][\"ground_truth\"])\n",
    "\n",
    "# Теперь user_prompts можно использовать для подачи в GPT API, где prompt — это вся история + новые фильмы для оценки,\n",
    "# а ground_truth — настоящие оценки для проверки результата.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import collections\n",
    "import copy\n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "import six\n",
    "import tqdm\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = '{{}}' # указываем токен\n",
    "\n",
    "def get_gpt_response(passage_prompt):\n",
    "    content = json.dumps(passage_prompt, ensure_ascii=False)\n",
    "    response = requests.post(\n",
    "        url='',\n",
    "        headers={\n",
    "            'Authorization': f'OAuth {TOKEN}',\n",
    "            'Ya-User': '', # Здесь указываем свой логин\n",
    "            'Content-Type': 'application/json',\n",
    "        },\n",
    "        json={\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": content}\n",
    "            ],\n",
    "            \"model\": \"gpt-4o-2024-05-13\"\n",
    "        }\n",
    "    )\n",
    "    if response.json().get('response', {}).get('choices') is not None:\n",
    "        return response.json()['response']['choices'][0]['message']['content']\n",
    "    print(response.json())\n",
    "    return None\n",
    "\n",
    "def apply_to(inputs):\n",
    "    gpt_answers = list()\n",
    "\n",
    "    for text in tqdm.tqdm(inputs, total=len(inputs)):\n",
    "        answer = get_gpt_response(text)\n",
    "        if answer is None:\n",
    "            break\n",
    "\n",
    "        gpt_answers.append(answer)\n",
    "\n",
    "    return gpt_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [dialog['prompt'] for dialog in user_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diplom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
